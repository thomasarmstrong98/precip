{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from precip.data.dataset import SwedishPrecipitationDataset, InfiniteSampler, npy_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = SwedishPrecipitationDataset(\n",
    "    split='train'\n",
    ")\n",
    "validation_dataset = SwedishPrecipitationDataset(\n",
    "    split='val'\n",
    ")\n",
    "\n",
    "sampler = InfiniteSampler(training_dataset)\n",
    "training_dataloader = DataLoader(dataset=training_dataset, sampler=sampler, batch_size=8)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, sampler=sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def padded_reshape(x: torch.Tensor, y: torch.Tensor):\n",
    "    \"\"\"Aligns last two dimensions of y to x via padding.\"\"\"\n",
    "    diffY = x.size(-2) - y.size(-2)\n",
    "    diffX = x.size(-1) - y.size(-1)\n",
    "    \n",
    "    y = F.pad(y, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "    return y\n",
    "\n",
    "\n",
    "def unet_up_collate(x: torch.Tensor, y: torch.Tensor, dim: int = 1):\n",
    "    y = padded_reshape(x, y)\n",
    "    return torch.cat([x, y], dim=dim)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, mid_channels: Optional[int] = None, kernel_size: int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        if mid_channels is None:\n",
    "            mid_channels = out_channels\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        )\n",
    "        \n",
    "        self.single_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.double_conv(x) + self.single_conv(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscales with maxpool and a double convolution\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, pool_factor: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(pool_factor), DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "    \n",
    "    \n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "            \n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_channels, in_channels // 2, kernel_size=2, stride=2\n",
    "            )\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "            \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        return self.conv(unet_up_collate(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_seq_len: int, output_seq_len: int, base_channels: int = 64, bilinear_upsample: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_channels = input_seq_len\n",
    "        self.bilinear = bilinear_upsample\n",
    "        self.base_channels = base_channels\n",
    "        self.output_channels = output_seq_len\n",
    "        factor = 2 if self.bilinear else 1\n",
    "        \n",
    "        # expands in our observation domain\n",
    "        self.inc = DoubleConv(self.n_channels, self.base_channels)\n",
    "        \n",
    "        # iteratively downsample in spatial dimension  \n",
    "        self.down1 = Down(self.base_channels * 1, self.base_channels * 2)\n",
    "        self.down2 = Down(self.base_channels * 2, self.base_channels * 4)\n",
    "        self.down3 = Down(self.base_channels * 4, self.base_channels * 8)\n",
    "        self.down4 = Down(self.base_channels * 8, self.base_channels * 16 // factor)\n",
    "        \n",
    "        # iteratively upsample\n",
    "        self.up4 = Up(self.base_channels * 16, self.base_channels * 8 // factor, self.bilinear)\n",
    "        self.up3 = Up(self.base_channels * 8, self.base_channels * 4 // factor, self.bilinear)\n",
    "        self.up2 = Up(self.base_channels * 4, self.base_channels * 2 // factor, self.bilinear)\n",
    "        self.up1 = Up(self.base_channels * 2, self.base_channels, self.bilinear)\n",
    "        \n",
    "        # collapse channels\n",
    "        self.out = nn.Conv2d(self.base_channels, self.output_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up4(x5, x4)\n",
    "        x = self.up3(x, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up1(x, x1)\n",
    "        \n",
    "        return self.out(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(8, 1, base_channels=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    model_name: str = \"convlstm_basic\"\n",
    "    batch_size: int = 4\n",
    "    number_of_steps: int = 10\n",
    "    training_size_per_step: int = 500\n",
    "    validation_size_per_step: int = 100\n",
    "    lr: float = 3e-3\n",
    "    lr_scheduler_step: int = 3\n",
    "    lr_scheduler_gamma: float = 0.85\n",
    "    weight_decay: float = 1e-9\n",
    "    intermediate_checkpointing: bool = False\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import CenterCrop\n",
    "\n",
    "train_dataiter = iter(dataloader)\n",
    "output_transform = CenterCrop((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomasarmstrong98\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "cat: /sys/module/amdgpu/initstate: No such file or directory\n",
      "ERROR:root:Driver not initialized (amdgpu not found in modules)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tom/dev/precip/wandb/run-20240211_132109-q6h3o4py</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thomasarmstrong98/precip/runs/q6h3o4py' target=\"_blank\">beaming-dragon-49</a></strong> to <a href='https://wandb.ai/thomasarmstrong98/precip' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thomasarmstrong98/precip' target=\"_blank\">https://wandb.ai/thomasarmstrong98/precip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thomasarmstrong98/precip/runs/q6h3o4py' target=\"_blank\">https://wandb.ai/thomasarmstrong98/precip/runs/q6h3o4py</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"precip\"\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.lr_scheduler_gamma)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    threshold=0.1,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=3,\n",
    ")\n",
    "\n",
    "def train(number_of_batches: int = 1_000) -> float:\n",
    "    model.train()\n",
    "    loss_history = list()\n",
    "\n",
    "    for _ in tqdm(range(number_of_batches)):\n",
    "        (batch_X, batch_y) = next(train_dataiter)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.squeeze(dim=1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_X)\n",
    "        # out.register_hook(lambda grad: grad * mask)\n",
    "        _loss = loss(output_transform(out), output_transform(batch_y))\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(np.sqrt(_loss.item()))\n",
    "\n",
    "    return np.mean(loss_history)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(number_of_batches: int = 300) -> float:\n",
    "    model.eval()\n",
    "    validation_loss_history = list()\n",
    "\n",
    "    for _ in tqdm(range(number_of_batches)):\n",
    "        batch_X, batch_y = next(val_dataiter)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        out = model(batch_X)\n",
    "        validation_loss_history.append(np.sqrt(loss(out, batch_y).item()))\n",
    "    return np.mean(validation_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:17<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:17<00:00,  1.58it/s]\n",
      "100%|██████████| 500/500 [05:17<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:18<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:19<00:00,  1.56it/s]\n",
      "100%|██████████| 500/500 [05:18<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:17<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:17<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:18<00:00,  1.57it/s]\n",
      "100%|██████████| 500/500 [05:17<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import precip\n",
    "import string\n",
    "\n",
    "folder_name = (\n",
    "    Path(precip.__file__).parents[1]\n",
    "    / \"checkpoints\"\n",
    "    / (wandb.run.name + \"\".join(random.choices(string.ascii_uppercase + string.digits, k=5)))\n",
    ")\n",
    "folder_name.mkdir(parents=True, exist_ok=True)\n",
    "for step_num in range(0, config.number_of_steps):\n",
    "        train_loss = train(config.training_size_per_step)\n",
    "        val_loss = test(config.validation_size_per_step)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        number_of_obs = (\n",
    "            config.batch_size\n",
    "            * config.training_size_per_step\n",
    "            * config.number_of_steps\n",
    "            * (step_num + 1)\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"total_number_observations\": number_of_obs,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "            },\n",
    "            folder_name / f\"step_num_{step_num}\",\n",
    "        )\n",
    "\n",
    "        wandb.log({\"loss\": {\"train\": np.mean(train_loss), \"val\": np.mean(val_loss)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
