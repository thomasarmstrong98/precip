{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import precip\n",
    "import wandb\n",
    "from precip.config import LOCAL_PRECIP_BOUNDARY_MASK\n",
    "from precip.data.dataset import InfiniteSampler, SwedishPrecipitationDataset, npy_loader\n",
    "from precip.models.unet import UNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (truncated file: eof = 9140844731, sblock->base_addr = 0, stored_eof = 14888424622)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_dataset \u001b[39m=\u001b[39m SwedishPrecipitationDataset(split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, scale\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/dev/precip/precip/data/dataset.py:39\u001b[0m, in \u001b[0;36mSwedishPrecipitationDataset.__init__\u001b[0;34m(self, root, observation_frequency_5_min, lookback_start_5_mins, lookback_intervals_5_mins_multiple, forecast_horizon_5_mins, split, scale)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforecast_horizon_5_mins \u001b[39m=\u001b[39m forecast_horizon_5_mins\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m scale\n\u001b[0;32m---> 39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(root)\n",
      "File \u001b[0;32m~/dev/precip/precip/data/dataset.py:42\u001b[0m, in \u001b[0;36mSwedishPrecipitationDataset.load\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m, root: Path):\n\u001b[0;32m---> 42\u001b[0m     data \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(root)\n\u001b[1;32m     43\u001b[0m     keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m     44\u001b[0m     \u001b[39m# keys = list(data.keys())[self.lookback_start_5_mins +1: ]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpg/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpg/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to synchronously open file (truncated file: eof = 9140844731, sblock->base_addr = 0, stored_eof = 14888424622)"
     ]
    }
   ],
   "source": [
    "training_dataset = SwedishPrecipitationDataset(split=\"train\", scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = SwedishPrecipitationDataset(split=\"val\", scale=True)\n",
    "\n",
    "training_sampler = InfiniteSampler(training_dataset, shuffle=True)\n",
    "validation_sampler = InfiniteSampler(validation_dataset, shuffle=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    training_dataset, sampler=training_sampler, batch_size=2, num_workers=12\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    validation_dataset, sampler=validation_sampler, batch_size=2, num_workers=12\n",
    ")\n",
    "train_dataiter, val_dataiter = iter(dataloader), iter(val_dataloader)\n",
    "\n",
    "mask = npy_loader(LOCAL_PRECIP_BOUNDARY_MASK)\n",
    "model = Model(\n",
    "    input_channels=1, hidden_channels=[64], kernel_size=(3, 3), num_layers=1, mask=mask\n",
    ").to(device)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.lr_scheduler_gamma)\n",
    "\n",
    "def train(number_of_batches: int = 1_000) -> float:\n",
    "    model.train()\n",
    "    loss_history = list()\n",
    "\n",
    "    for _ in tqdm(range(number_of_batches)):\n",
    "        (batch_X, batch_y) = next(train_dataiter)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_X)\n",
    "        _loss = loss(out, batch_y)\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(_loss.item())\n",
    "\n",
    "    return np.mean(loss_history)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(number_of_batches: int = 300) -> float:\n",
    "    model.eval()\n",
    "    validation_loss_history = list()\n",
    "\n",
    "    for _ in tqdm(range(number_of_batches)):\n",
    "        batch_X, batch_y = next(val_dataiter)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        out = model(batch_X)\n",
    "        validation_loss_history.append(loss(out, batch_y).item())\n",
    "    return np.mean(validation_loss_history)\n",
    "\n",
    "folder_name = (\n",
    "    Path(precip.__file__).parents[1]\n",
    "    / \"checkpoints\"\n",
    "    / (wandb.run.name + \"\".join(random.choices(string.ascii_uppercase + string.digits, k=5)))\n",
    ")\n",
    "folder_name.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for step_num in range(0, config.number_of_steps):\n",
    "    train_loss = train(config.training_size_per_step)\n",
    "    val_loss = test(config.validation_size_per_step)\n",
    "    scheduler.step()\n",
    "\n",
    "    number_of_obs = (\n",
    "        config.batch_size\n",
    "        * config.training_size_per_step\n",
    "        * config.number_of_steps\n",
    "        * (step_num + 1)\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"total_number_observations\": number_of_obs,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "        },\n",
    "        folder_name / f\"step_num_{step_num}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
